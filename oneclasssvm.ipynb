{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to use SKLearn's One Class SVM to rank ARID crops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model = nn.Sequential(*list(model.children())[:-1])\n",
    "model.eval()\n",
    "\n",
    "img_size = 256\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "webly_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeblyNormDataset(Dataset):\n",
    "\n",
    "    def __init__(self, webly_root, search_term, transform, dloader=True):\n",
    "        self.webly_root = Path(webly_root)\n",
    "        self.transform = transform\n",
    "        self.items = []\n",
    "        self.dloader = dloader\n",
    "        \n",
    "        for engine in self.webly_root.iterdir():  \n",
    "            if engine.stem != '.floyddata':\n",
    "                for search in engine.iterdir():\n",
    "                    if search.stem == search_term:\n",
    "                        for img in Path(search / 'images').iterdir():\n",
    "                            self.items.append(img)\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.items[idx]\n",
    "        img = Image.open(path)\n",
    "        img = img.convert('RGB')\n",
    "        sample = self.transform(img)\n",
    "        if self.dloader:\n",
    "            return sample\n",
    "        else:\n",
    "            return sample, path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicates.\n",
    "dist = WeblyNormDataset('/home/justin/Desktop/webly-dataset/', 'yellow_lemon_fruit', webly_transform, dloader=False)\n",
    "results = {}\n",
    "zero = torch.zeros([1, 1280, 8, 8])\n",
    "with torch.no_grad():\n",
    "    for i, pth in tqdm(dist):\n",
    "        rel_path = Path((*pth.parts[pth.parts.index('webly-dataset')+1:]))\n",
    "        o = model(i.unsqueeze(0))\n",
    "        b = torch.dist(zero, o)\n",
    "        results[rel_path] = b.item()\n",
    "        \n",
    "print(len(results))    \n",
    "_results = {v:k for k,v in results.items()}\n",
    "_results = {v:k for k,v in _results.items()}\n",
    "print(len(_results))\n",
    "f = list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneClassSVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.fit_predict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arid import arid\n",
    "from PIL import ImageDraw, Image\n",
    "from IPython.display import display\n",
    "wps = arid.get_wps(\"/home/justin/Desktop/arid-dataset\")\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import skimage.io\n",
    "\n",
    "wp = wps[134]\n",
    "\n",
    "quality = 'single'\n",
    "title = wp.get_title()\n",
    "with open(f'/home/justin/Desktop/thesis/ss/ss-{quality}-{title}.json') as json_file:\n",
    "    ss_data = json.load(json_file)\n",
    "\n",
    "img_paths = wp.rgb_image_paths()\n",
    "for img_path in img_paths:\n",
    "    image = skimage.io.imread(img_path)\n",
    "    img = Image.open(img_path)\n",
    "    new_img_path = arid.annotation_path(img_path, 'selective-search')\n",
    "    img_key = Path(img_path).stem\n",
    "    \n",
    "    annotations = []\n",
    "    top_score = 0\n",
    "    for box in ss_data[img_key]['boxes']:\n",
    "        x1 = box[0]\n",
    "        y1 = box[1]\n",
    "        x2 = box[2]\n",
    "        y2 = box[3]\n",
    "        \n",
    "        crop = img.crop((x1, y1, x2, y2))\n",
    "        t_crop = test_transform(crop)\n",
    "        features = model(t_crop.unsqueeze(0))\n",
    "        features = features.flatten().detach().numpy().tolist()\n",
    "        score = clf.score_samples([features])\n",
    "        annotations.append({\n",
    "            'id': 'test',\n",
    "            'coords': [(x1,y1), (x2, y1), (x2, y2), (x1,y2)],\n",
    "            'score': score,\n",
    "            'colormap': 'YlGn'\n",
    "        })\n",
    "\n",
    "\n",
    "#     gt_annotations_raw = wp.get_annotations(img_path.stem)['annotations']\n",
    "#     gt_annotations = []\n",
    "#     for gt_annotation_raw in gt_annotations_raw:\n",
    "#         if gt_annotation_raw['id'] is not None:\n",
    "#             x = gt_annotation_raw['x']\n",
    "#             y = gt_annotation_raw['y']\n",
    "#             w = gt_annotation_raw['width']\n",
    "#             h = gt_annotation_raw['height']\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "for dz in annotations:\n",
    "    if dz['score'][0] > 394:\n",
    "        g = {}\n",
    "        g['id'] = dz['id']\n",
    "        g['coords'] = dz['coords']\n",
    "        g['colormap'] = dz['colormap']\n",
    "        g['score'] = dz['score'][0]\n",
    "        b.append(g)\n",
    "\n",
    "img2 = img.copy()\n",
    "arid.annotate_img(img2, new_img_path, b, save=False)\n",
    "display(img2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
